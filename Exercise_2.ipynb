{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**DISCLAIMER:** Since the exam asks to show what I did to solve the question, I am showing it, even if my notebook looks a bit messy. Otherwise, I would have made my notebook look better.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEPARTURES (This was the last file I was working on):**\n",
    "\n",
    "Link: https://www.flightstats.com/v2/flight-tracker/departures/MEX/?year=2021&month=1&date=19&hour=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data from the time: 0 has been scraped!\n",
      "Message: chrome not reachable\n",
      "  (Session info: chrome=88.0.4324.96)\n",
      "\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=88.0.4324.96)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aa119731c9b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m                         \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                         \u001b[0mCompany\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//div[contains(@class, 'ticket__FlightNumberContainer')]/div[contains(@class, 'text-helper__TextHelper')][last()]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m                         \u001b[0mFlight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//div[contains(@class, 'ticket__FlightNumberContainer')]/div[contains(@class, 'text-helper__TextHelper')][1]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=88.0.4324.96)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aa119731c9b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# In case an error appears, I return to the main page to continue doing web scraping.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mpags_button\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[last()-1]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mback\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m--> 813\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGO_BACK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=88.0.4324.96)\n"
     ]
    }
   ],
   "source": [
    "import random, csv\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "opts = Options()\n",
    "opts.add_argument(\"user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/88.0.4324.96 Chrome/88.0.4324.96 Safari/537.36\")\n",
    "driver = webdriver.Chrome('./chromedriver', options=opts) # Using the object driver, I'll do the web scraping\n",
    "\n",
    "# Seed URL:\n",
    "driver.get(\"https://www.flightstats.com/v2/flight-tracker/departures/MEX/\")\n",
    "\n",
    "with open(\"departures.csv\", 'w') as file_obj:\n",
    "    csv_writer = csv.writer(file_obj)\n",
    "    \n",
    "    cols = [\"Company\", \"Flight\", \"From\", \"To\", \"Status\", \"Scheduled_Departure_Hour_CST\", \"Real_Departure_Hour_CST\", \"Flight_Departure_Times\"]\n",
    "    csv_writer.writerow([col_name for col_name in cols])\n",
    "\n",
    "    for day in ['19-1-2021','20-1-2021']:\n",
    "        day_button = driver.find_element_by_xpath(f\"//select[@name='date']/option[@value='{day}']\")\n",
    "        day_button.click()\n",
    "        sleep(random.uniform(1,1.5))\n",
    "\n",
    "        for time in ['0','6','12','18']:\n",
    "            time_button = driver.find_element_by_xpath(f\"//select[@name='time']/option[@value='{time}']\")\n",
    "            time_button.click()\n",
    "            sleep(random.uniform(1,1.5))\n",
    "\n",
    "            refresh_button = driver.find_element_by_xpath(\"//span[text()='Refine Search']\")\n",
    "            refresh_button.click()\n",
    "            sleep(random.uniform(1,1.5))\n",
    "            \n",
    "            flag, counter = False, 1\n",
    "            while True:\n",
    "                \n",
    "                \"\"\"\n",
    "                if pagination_numbers[0] < pagination_numbers[1]:\n",
    "                    pags_button = driver.find_element_by_xpath(\"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[last()-1]\")\n",
    "                    pags_button.click()\n",
    "                    pagination_numbers.pop(0)\n",
    "                    sleep(random.uniform(1,1.5))\n",
    "                else:\n",
    "                    break\n",
    "                \"\"\"\n",
    "                \n",
    "                flights_links = driver.find_elements(By.XPATH, \"//a[@class='table__A-s1x7nv9w-2 flrJsE']\")\n",
    "                flights_per_page = list()\n",
    "                for a_link in flights_links:\n",
    "                    flights_per_page.append(a_link.get_attribute('href'))\n",
    "\n",
    "                for link in flights_per_page:\n",
    "                    try:\n",
    "                        # Obtaining the data for every flight:\n",
    "                        driver.get(link) # I get inside the details of the flight.\n",
    "                        sleep(random.uniform(0.5,1.0))\n",
    "                        Company = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__FlightNumberContainer')]/div[contains(@class, 'text-helper__TextHelper')][last()]\").text\n",
    "                        Flight = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__FlightNumberContainer')]/div[contains(@class, 'text-helper__TextHelper')][1]\").text\n",
    "                        From = driver.find_element(By.XPATH, \"//div[contains(@class, 'route-with-plane__Route-s154xj1h-1')][1]//div[contains(@class, 'text-helper__TextHelper')][last()]\").text\n",
    "                        To = driver.find_element(By.XPATH, \"//div[contains(@class, 'route-with-plane__Route-s154xj1h-1')][last()]//div[contains(@class, 'text-helper__TextHelper')][last()]\").text\n",
    "                        Status = driver.find_element(By.XPATH, \"//div[contains(@class,'ticket__StatusContainer')]/div[1]\").text\n",
    "                        Scheduled_Departure_Hour = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__TicketContent')]/div[1]/div[contains(@class, 'ticket__TimeGroupContainer')]/div[1]/div[last()]\").text\n",
    "                        Real_Departure_Hour = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__TicketContent')]/div[1]/div[contains(@class, 'ticket__TimeGroupContainer')]/div[2]/div[last()]\").text\n",
    "                        Flight_Departure_Times = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__TicketContent')]/div[1]/div[contains(@class, 'ticket__InfoSection')][last()]/div[last()]\").text\n",
    "                        driver.back() # I return to the main page.\n",
    "                        \n",
    "                        # Storing the data inside an \"csv\" file:\n",
    "                        flight_data = [Company, Flight, From, To, Status, Scheduled_Departure_Hour, Real_Departure_Hour, Flight_Departure_Times]\n",
    "                        csv_writer.writerow([data.replace('CST','') if data != '--' else \"Unknown\" for data in flight_data])\n",
    "                        \n",
    "                        sleep(random.uniform(0.5,1.0))\n",
    "                        \n",
    "                    except Exception as error:\n",
    "                        print(error)\n",
    "                        driver.back() # In case an error appears, I return to the main page to continue doing web scraping.\n",
    "                \n",
    "                pags_button = driver.find_element_by_xpath(\"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[last()-1]\")\n",
    "                pags_button.click()\n",
    "                sleep(random.uniform(1,1.5))\n",
    "                \n",
    "                if flag == False:\n",
    "                    cantidad_pags = driver.find_element(By.XPATH, \"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[last()-2]\").text\n",
    "                    # Just in case we have more than 3 pages per period of time:\n",
    "                    if cantidad_pags:\n",
    "                        pass\n",
    "                    else:\n",
    "                        cantidad_pags = driver.find_element(By.XPATH, \"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[5]\").text\n",
    "                    flag = True\n",
    "                    \n",
    "                if counter >= int(cantidad_pags):\n",
    "                    break\n",
    "                    \n",
    "                counter += 1\n",
    "                \n",
    "            \n",
    "            print(f\"The data from the time: {time} has been scraped!\")\n",
    "                \n",
    "        print(f\"The whole data from the day: {day} has been scraped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARRIVALS:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://www.flightstats.com/v2/flight-tracker/arrivals/MEX/?year=2021&month=1&date=19&hour=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, csv\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "opts = Options()\n",
    "opts.add_argument(\"user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/88.0.4324.96 Chrome/88.0.4324.96 Safari/537.36\")\n",
    "driver = webdriver.Chrome('./chromedriver', options=opts) # Using the object driver, I'll do the web scraping\n",
    "\n",
    "# Seed URL:\n",
    "driver.get(\"https://www.flightstats.com/v2/flight-tracker/departures/MEX/\")\n",
    "\n",
    "with open(\"departures.csv\", 'w') as file_obj:\n",
    "    csv_writer = csv.writer(file_obj)\n",
    "    \n",
    "    cols = [\"Company\", \"Flight\", \"From\", \"To\", \"Status\", \"Scheduled_Departure_Hour_CST\", \"Real_Departure_Hour_CST\", \"Flight_Departure_Times\"]\n",
    "    csv_writer.writerow([col_name for col_name in cols])\n",
    "\n",
    "    for day in ['19-1-2021','20-1-2021']:\n",
    "        day_button = driver.find_element_by_xpath(f\"//select[@name='date']/option[@value='{day}']\")\n",
    "        day_button.click()\n",
    "        sleep(random.uniform(1,1.5))\n",
    "\n",
    "        for time in ['0','6','12','18']:\n",
    "            time_button = driver.find_element_by_xpath(f\"//select[@name='time']/option[@value='{time}']\")\n",
    "            time_button.click()\n",
    "            sleep(random.uniform(1,1.5))\n",
    "\n",
    "            refresh_button = driver.find_element_by_xpath(\"//span[text()='Refine Search']\")\n",
    "            refresh_button.click()\n",
    "            sleep(random.uniform(1,1.5))\n",
    "            \n",
    "            pagination_numbers = [1,]\n",
    "            while True:\n",
    "\n",
    "                flights_links = driver.find_elements(By.XPATH, \"//a[@class='table__A-s1x7nv9w-2 flrJsE']\")\n",
    "                flights_per_page = []\n",
    "                for a_link in flights_links:\n",
    "                    flights_per_page.append(a_link.get_attribute('href'))\n",
    "\n",
    "                for link in flights_per_page:\n",
    "                    try:\n",
    "                        # Obtaining the data for every flight:\n",
    "                        driver.get(link) # I get inside the details of the flight.\n",
    "                        sleep(random.uniform(0.5,1.0))\n",
    "                        Company = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__FlightNumberContainer')]/div[contains(@class, 'text-helper__TextHelper')][last()]\").text\n",
    "                        Flight = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__FlightNumberContainer')]/div[contains(@class, 'text-helper__TextHelper')][1]\").text\n",
    "                        From = driver.find_element(By.XPATH, \"//div[contains(@class, 'route-with-plane__Route-s154xj1h-1')][1]//div[contains(@class, 'text-helper__TextHelper')][last()]\").text\n",
    "                        To = driver.find_element(By.XPATH, \"//div[contains(@class, 'route-with-plane__Route-s154xj1h-1')][last()]//div[contains(@class, 'text-helper__TextHelper')][last()]\").text\n",
    "                        Status = driver.find_element(By.XPATH, \"//div[contains(@class,'ticket__StatusContainer')]/div[1]\").text\n",
    "                        Scheduled_Departure_Hour = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__TicketContent')]/div[1]/div[contains(@class, 'ticket__TimeGroupContainer')]/div[1]/div[last()]\").text\n",
    "                        Real_Departure_Hour = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__TicketContent')]/div[1]/div[contains(@class, 'ticket__TimeGroupContainer')]/div[2]/div[last()]\").text\n",
    "                        Flight_Departure_Times = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__TicketContent')]/div[1]/div[contains(@class, 'ticket__InfoSection')][last()]/div[last()]\").text\n",
    "                        driver.back() # I return to the main page.\n",
    "                        \n",
    "                        # Storing the data inside an \"csv\" file:\n",
    "                        flight_data = [Company, Flight, From, To, Status, Scheduled_Departure_Hour, Real_Departure_Hour, Flight_Departure_Times]\n",
    "                        csv_writer.writerow([data.replace('CST','') if data != '--' else \"Unknown\" for data in flight_data])\n",
    "                        \n",
    "                        sleep(random.uniform(0.5,1.0))\n",
    "                        \n",
    "                    except Exception as error:\n",
    "                        print(error)\n",
    "                        driver.back() # In case an error appears, I return to the main page to continue doing web scraping.\n",
    "\n",
    "                pag = driver.find_element(By.XPATH, \"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[last()-2]\").text\n",
    "                # Just in case we have more than 3 pages per period of time:\n",
    "                if pag:\n",
    "                    pagination_numbers.append(int(pag))\n",
    "                else:\n",
    "                    pag = driver.find_element(By.XPATH, \"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[5]\").text\n",
    "                    pagination_numbers.append(int(pag))\n",
    "                \n",
    "                if pagination_numbers[0] < pagination_numbers[1]:\n",
    "                    pags_button = driver.find_element_by_xpath(\"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[last()-1]\")\n",
    "                    pags_button.click()\n",
    "                    pagination_numbers.pop(0)\n",
    "                    sleep(random.uniform(1,1.5))\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "        print(f\"The whole data from the day: {day} has been scraped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keeping save the code that works (just in case something goes wrong):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, csv\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "opts = Options()\n",
    "opts.add_argument(\"user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 Safari/537.36\")\n",
    "driver = webdriver.Chrome('./chromedriver', options=opts) # Using the object driver, I'll do the web scraping\n",
    "\n",
    "# To go to the website I want to:\n",
    "driver.get(\"https://www.flightstats.com/v2/flight-tracker/departures/MEX/?year=2021&month=1&date=18&hour=0\")\n",
    "\n",
    "with open(\"departures.csv\", 'w') as file_obj:\n",
    "    csv_writer = csv.writer(file_obj)\n",
    "    \n",
    "    cols = [\"Company\", \"Flight\", \"From\", \"To\", \"Status\", \"Scheduled_Departure_Hour_CST\", \"Real_Departure_Hour_CST\", \"Flight_Departure_Times\"]\n",
    "    csv_writer.writerow([col_name for col_name in cols])\n",
    "\n",
    "    for day in ['18-1-2021','19-1-2021']:\n",
    "        day_button = driver.find_element_by_xpath(f\"//select[@name='date']/option[@value='{day}']\")\n",
    "        day_button.click()\n",
    "        sleep(random.uniform(1,1.5))\n",
    "\n",
    "        for time in ['0','6','12','18']:\n",
    "            time_button = driver.find_element_by_xpath(f\"//select[@name='time']/option[@value='{time}']\")\n",
    "            time_button.click()\n",
    "            sleep(random.uniform(1,1.5))\n",
    "\n",
    "            refresh_button = driver.find_element_by_xpath(\"//span[text()='Refine Search']\")\n",
    "            refresh_button.click()\n",
    "            sleep(random.uniform(1,1.5))\n",
    "\n",
    "            while True:\n",
    "\n",
    "                flights_links = driver.find_elements(By.XPATH, \"//a[@class='table__A-s1x7nv9w-2 flrJsE']\")\n",
    "                flights_per_page = []\n",
    "                for a_link in flights_links:\n",
    "                    flights_per_page.append(a_link.get_attribute('href'))\n",
    "\n",
    "                for link in flights_per_page:\n",
    "                    try:\n",
    "                        # Obtaining the data for every flight:\n",
    "                        driver.get(link) # I get inside the details of the flight.\n",
    "                        sleep(random.uniform(1,1.5))\n",
    "                        Company = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__FlightNumberContainer')]/div[contains(@class, 'text-helper__TextHelper')][last()]\").text\n",
    "                        Flight = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__FlightNumberContainer')]/div[contains(@class, 'text-helper__TextHelper')][1]\").text\n",
    "                        From = driver.find_element(By.XPATH, \"//div[contains(@class, 'route-with-plane__Route-s154xj1h-1')][1]//div[contains(@class, 'text-helper__TextHelper')][last()]\").text\n",
    "                        To = driver.find_element(By.XPATH, \"//div[contains(@class, 'route-with-plane__Route-s154xj1h-1')][last()]//div[contains(@class, 'text-helper__TextHelper')][last()]\").text\n",
    "                        Status = driver.find_element(By.XPATH, \"//div[contains(@class,'ticket__StatusContainer')]/div[1]\").text\n",
    "                        Scheduled_Departure_Hour = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__TicketContent')]/div[1]/div[contains(@class, 'ticket__TimeGroupContainer')]/div[1]/div[last()]\").text\n",
    "                        Real_Departure_Hour = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__TicketContent')]/div[1]/div[contains(@class, 'ticket__TimeGroupContainer')]/div[2]/div[last()]\").text\n",
    "                        Flight_Departure_Times = driver.find_element(By.XPATH, \"//div[contains(@class, 'ticket__TicketContent')]/div[1]/div[contains(@class, 'ticket__InfoSection')][last()]/div[last()]\").text\n",
    "                        driver.back() # I return to the main page.\n",
    "                        \n",
    "                        # Storing the data inside an \"csv\" file:\n",
    "                        flight_data = [Company, Flight, From, To, Status, Scheduled_Departure_Hour, Real_Departure_Hour, Flight_Departure_Times]\n",
    "                        csv_writer.writerow([data.replace('CST','') if data != '--' else \"Unknown\" for data in flight_data])\n",
    "                        \n",
    "                        sleep(random.uniform(0.5,1.0))\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print (e)\n",
    "                        driver.back() # If there's a mistake I return to the main page.\n",
    "\n",
    "                try:\n",
    "                    pags_button = driver.find_element_by_xpath(\"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[last()-1]\")\n",
    "                    pags_button.click()\n",
    "                    sleep(random.uniform(1,1.5))\n",
    "                except:\n",
    "                    print(f\"The data from the day: {day} has been scraped!\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derecha_arriba = \"//div[contains(@class,'table__CodeshareAndPagination')]/div[last()]/div/div/div[last()-1]\"\n",
    "derecha_abajo = \"//div[contains(@class,'table__TableContainer')]/div[last()]/div/div[last()-1]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text-helper__TextHelper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
